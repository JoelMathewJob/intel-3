# ğŸ§  Case Intelligence: Multimodal RAG with Docling & Chroma

An advanced **Retrieval-Augmented Generation (RAG)** system designed for comprehensive case management.

This system processes **PDFs, Images, Audio, and Video** into a unified vector database using:

- **Docling** â†’ Structured document parsing  
- **Whisper (ASR)** â†’ Speech-to-text transcription  
- **Azure GPT-4 Vision** â†’ Visual scene understanding + OCR  
- **ChromaDB** â†’ Persistent hybrid vector database  

---

# ğŸ› ï¸ Prerequisites

## 1ï¸âƒ£ Python
- Install **Python 3.10 or 3.11**
- Verify:
```bash
python --version
```

---

## 2ï¸âƒ£ FFmpeg (Required for Audio/Video Processing)

### âœ… Windows (Recommended)
```bash
winget install ffmpeg
```

### Alternative (Chocolatey)
```bash
choco install ffmpeg
```

Verify installation:
```bash
ffmpeg -version
```

---

## 3ï¸âƒ£ Install `uv` (Recommended Package Manager)

### Windows (PowerShell)
```bash
winget install AstralSh.uv
```

### macOS / Linux
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Verify:
```bash
uv --version
```

> You may use `pip`, but **uv is faster and recommended**.

---

# ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ main.py              # Ingestion script (Uploads & Parses)
â”œâ”€â”€ chat2.py             # RAG Chat interface
â”œâ”€â”€ .env                 # API Keys and Secrets
â”œâ”€â”€ parsers/
â”‚   â””â”€â”€ all_parser8.py   # Multimodal SmartDocumentParser
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/         # Drop raw files here
â”‚   â”œâ”€â”€ output/          # Parsed Markdown, JSON, Images
â”‚   â””â”€â”€ chroma_db/       # Persistent Vector Database
â””â”€â”€ README.md
```

---

# âš™ï¸ Setup & Installation

## 1ï¸âƒ£ Navigate to Project

```bash
cd intel-3
```

---

## 2ï¸âƒ£ Create `.env` File

Create a `.env` file in the root directory:

```env
AZURE_OPENAI_API_KEY=your_azure_key_here
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/

# Optional (for Hugging Face transcription fallback)
HF_TOKEN=your_token_here
```

---

## 3ï¸âƒ£ Install Dependencies

### âœ… Using `uv` (Preferred)

```bash
git clone <repo>
cd intel-3
uv sync

```

If `uv sync` removes Whisper accidentally:

```bash
uv pip install openai-whisper
```

---

### Alternative: Using pip

```bash
pip install "docling[asr]" openai-whisper opencv-python chromadb python-dotenv requests langchain-huggingface
```

---

# ğŸš€ How to Use

---

# 1ï¸âƒ£ Ingesting Documents (Upload Phase)

### Step 1 â€” Add Files

Place your files into:

```
data/input/
```

Supported formats:
- ğŸ“„ PDFs, Docs, xlsx
- ğŸ¥ MP4 videos
- ğŸ™ï¸ MP3 audio
- ğŸ–¼ï¸ Images (JPG, PNG, etc.)

---

### Step 2 â€” Run Ingestion

```bash
uv run main.py
```

When prompted:

```
Enter Collection Name: case_123
```

This creates your **Case Room** in ChromaDB.

---

## ğŸ”„ What Happens During Ingestion?

- PDFs â†’ Parsed into structured Markdown + JSON
- Videos â†’ Frames extracted every 4 seconds
- Azure Vision â†’ Scene description + OCR text
- Audio â†’ Whisper timestamped transcripts
- Everything â†’ Embedded and stored in ChromaDB with metadata

---

# 2ï¸âƒ£ Start the RAG Chat

Once ingestion is complete:

```bash
uv run chat2.py
```

You can now ask questions like:

- "What phone number appears on the sticker at the start of the video?"
- "Summarize the meeting audio."
- "What happens around timestamp 02:15?"
- "List all names mentioned in the transcript."

The assistant has access to:

- ğŸ“„ Parsed documents  
- ğŸ¥ Video frame descriptions  
- ğŸ‘ï¸ OCR extracted text  
- ğŸ™ï¸ Timestamped transcripts  
- ğŸ§  Metadata (timestamps, filenames, source references)  

---

# ğŸ” Advanced Features

## ğŸ¥ Video Visual Timeline
- Extracts frames every 4 seconds
- Uses Azure GPT-4 Vision for:
  - Scene understanding
  - OCR on signs, labels, stickers
- Indexed with timestamps for precise retrieval

---

## ğŸ™ï¸ Audio Intelligence
- Local Whisper via `docling[asr]`
- Timestamped transcripts
- Embedded for semantic search

---

## ğŸ” Hybrid Search (ChromaDB)
- Vector similarity search
- Metadata filtering (filename, timestamp)
- Enables citation of exact video moments

---

# âš ï¸ Troubleshooting

## âŒ WinError 2
FFmpeg is not in PATH.

Check:
```bash
ffmpeg -version
```

If not found, reinstall with:
```bash
winget install ffmpeg
```

---

## âŒ AttributeError (InputFormat)
Docling version issue. Upgrade:

```bash
uv pip install -U docling
```

---

## âŒ Hugging Face Connection Errors

After first successful model download, run offline mode:

### Windows
```powershell
$env:HF_HUB_OFFLINE=1
```

---

# ğŸ§  Architecture Overview

```
Multimodal Input (PDF / Video / Audio / Image)
            â†“
Docling / Whisper / Azure Vision
            â†“
Structured Content + Metadata
            â†“
Embeddings
            â†“
ChromaDB (Persistent Storage)
            â†“
RAG Chat Interface
```

---

# ğŸ“Œ Recommended Workflow

1. Install prerequisites
2. Configure `.env`
3. Drop files into `data/uploads`
4. Run `main.py`
5. Start `chat2.py`
6. Investigate your case intelligently

---

# ğŸš€ Future Enhancements (Optional Ideas)

- Role-based case rooms
- Timeline visualization dashboard
- Cross-case linking
- Evidence scoring system
- Multi-user collaboration
- Docker deployment

---

# ğŸ You're Ready

Your **Multimodal Case Intelligence RAG system** is now ready for intelligent investigation workflows.

Happy Investigating ğŸ”
